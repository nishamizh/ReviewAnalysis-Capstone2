{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c5e8ac0-e3f2-4bf5-a110-4d7c62b7bfee",
   "metadata": {},
   "source": [
    "# Data Pre- Processing for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdcddf4e-9009-43dd-87db-e99c2078d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import time # Import the time module\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('default')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1337b7ad-4b5b-4670-a948-174deaccdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('EDA_filtered_Rating_Amazon_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6128b53-0ba5-4756-94f5-07f199fd2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1800000, 15)\n",
      "Target shape: (1800000,)\n"
     ]
    }
   ],
   "source": [
    "# Step1 defining features and target\n",
    "\n",
    "# Define the target variable (y) and features (X)\n",
    "# The `Rating_Sentiment` column appears to be the target variable based on the data structure.\n",
    "# Features will be all numerical columns from 'Review_str_len' to the end.\n",
    "#X = data.loc[:, 'Review_str_len':'years']\n",
    "# Drop non-numeric columns except target/label\n",
    "X = data.drop(['Rating_Sentiment'], axis=1)\n",
    "y = data['Rating_Sentiment']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71bdd080-31e4-4eda-9708-315ac063b4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original classes: ['Negative' 'Neutral' 'Positive']\n",
      "Encoded labels: [0 1 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(f\"Original classes: {le.classes_}\")\n",
    "print(f\"Encoded labels: {np.unique(y_encoded)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b45d3d2-9f5c-4dda-814c-4198554b5cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (1260000, 15)\n",
      "Validation features shape: (540000, 15)\n",
      "Training target shape: (1260000,)\n",
      "Validation target shape: (540000,)\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Split the data into training and validation sets\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Validation features shape: {X_val.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"Validation target shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ede4991-5060-4cae-b34f-978b389399f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = 'WordNet_Lemmatizer'\n",
    "numerical_features = ['Review_str_len', 'Title_str_len', 'Review_wtoken_cnt', 'lexical_diversity', 'review_removed_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9dbc3f0-f4d8-45d6-a664-beda030a9338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing data transformations...\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Define the shared preprocessors and pre-compute data ---\n",
    "\n",
    "# Preprocessor for all models except Naive Bayes\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(max_features=500, stop_words='english'), text_features),\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Preprocessor specifically for Naive Bayes to handle non-negative inputs\n",
    "preprocessor_nb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(max_features=500, stop_words='english'), text_features),\n",
    "        ('num', MinMaxScaler(), numerical_features) # Using MinMaxScaler to prevent negative values\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# --- 2.1 Pre-compute the transformed data ONCE ---\n",
    "\n",
    "print(\"Pre-computing data transformations...\")\n",
    "\n",
    "# Data for Implementation 1: TF-IDF + StandardScaler\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "\n",
    "# Data for Implementation 2 & 3: TF-IDF + StandardScaler + PCA\n",
    "# We must first fit the preprocessor, then the PCA on the preprocessed data\n",
    "pipeline_PCA = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA(n_components=83)),\n",
    "])\n",
    "X_train_pca = pipeline_PCA.fit_transform(X_train, y_train)\n",
    "X_val_pca = pipeline_PCA.transform(X_val)\n",
    "\n",
    "# Data for Naive Bayes models (pre-computed separately to handle non-negativity)\n",
    "X_train_nb = preprocessor_nb.fit_transform(X_train)\n",
    "X_val_nb = preprocessor_nb.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "021fe348-eb37-40cf-8558-d7a9f74b52ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Create a dictionary of models to experiment with ---\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'NaiveBayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "# --- 4. Define parameter grids for each model ---\n",
    "param_grids = {\n",
    "    'LogisticRegression': {\n",
    "        'model__C': [0.1, 1.0, 10.0],\n",
    "        'model__solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.05, 0.1, 0.2]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [10, 20, None]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model__n_neighbors': [3, 5, 7],\n",
    "        'model__weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'NaiveBayes': {\n",
    "        'model__alpha': [0.1, 0.5, 1.0]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf392f2c-2fda-4366-b483-534dc305f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 5. Implementations ---\n",
    "\n",
    "print(\"\\n--- Implementation 1: Pipeline(TF-IDF + StandardScaler -> Model) ---\")\n",
    "for model_name, model_instance in models.items():\n",
    "    print(f\"\\nTraining and evaluating the {model_name} model...\")\n",
    "    try:\n",
    "        if model_name == 'NaiveBayes':\n",
    "            model_instance.fit(X_train_nb, y_train)\n",
    "            score = model_instance.score(X_val_nb, y_val)\n",
    "        else:\n",
    "            model_instance.fit(X_train_transformed, y_train)\n",
    "            score = model_instance.score(X_val_transformed, y_val)\n",
    "        \n",
    "        print(f\"Accuracy for {model_name}: {score:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while training {model_name}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67c265-92ac-4574-835f-f46a55b4f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Implementation 2: Pipeline(TF-IDF + StandardScaler -> PCA -> Model) ---\")\n",
    "for model_name, model_instance in models.items():\n",
    "    print(f\"\\nTraining and evaluating the {model_name} model...\")\n",
    "    try:\n",
    "        if model_name == 'NaiveBayes':\n",
    "            # Naive Bayes and PCA are incompatible because PCA produces negative values\n",
    "            print(f\"Skipping {model_name} as it is incompatible with PCA.\")\n",
    "            continue\n",
    "        \n",
    "        model_instance.fit(X_train_pca, y_train)\n",
    "        score = model_instance.score(X_val_pca, y_val)\n",
    "        \n",
    "        print(f\"Accuracy for {model_name}: {score:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while training {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10196c9-337d-479d-bffc-87c54dfff0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Implementation 3: Pipeline(TF-IDF + StandardScaler -> PCA -> Model) with GridSearchCV ---\n",
      "\n",
      "Performing GridSearchCV for the LogisticRegression model...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for LogisticRegression: {'model__C': 10.0, 'model__solver': 'lbfgs'}\n",
      "Validation Accuracy for the best LogisticRegression model: 0.6111\n",
      "\n",
      "Performing GridSearchCV for the XGBoost model...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:40:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:40:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:40:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:41:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:41:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:41:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:41:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:41:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:41:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:42:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:42:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:42:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:42:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:42:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:42:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:42:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:42:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:42:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:43:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for XGBoost: {'model__learning_rate': 0.2, 'model__n_estimators': 200}\n",
      "Validation Accuracy for the best XGBoost model: 0.6267\n",
      "\n",
      "Performing GridSearchCV for the RandomForest model...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for RandomForest: {'model__max_depth': None, 'model__n_estimators': 200}\n",
      "Validation Accuracy for the best RandomForest model: 0.6028\n",
      "\n",
      "Performing GridSearchCV for the KNN model...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Implementation 3: Pipeline(TF-IDF + StandardScaler -> PCA -> Model) with GridSearchCV ---\")\n",
    "best_models = {}\n",
    "\n",
    "# The PCA pipeline is defined outside the loop\n",
    "simplified_pca_pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=83)),\n",
    "])\n",
    "\n",
    "for model_name, model_instance in models.items():\n",
    "    print(f\"\\nPerforming GridSearchCV for the {model_name} model...\")\n",
    "    \n",
    "    param_grid = param_grids.get(model_name, {})\n",
    "    if not param_grid:\n",
    "        print(f\"No parameter grid defined for {model_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Create the full pipeline for GridSearchCV\n",
    "    # The preprocessor is no longer in the pipeline! It's pre-computed.\n",
    "    full_pipeline_gs = Pipeline([\n",
    "        ('model', model_instance)\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        # Check for NaiveBayes and handle its incompatibility with PCA\n",
    "        if model_name == 'NaiveBayes':\n",
    "            print(f\"Skipping GridSearchCV for {model_name} as it is incompatible with PCA.\")\n",
    "            continue\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            full_pipeline_gs, \n",
    "            param_grid, \n",
    "            cv=3, \n",
    "            scoring='accuracy', \n",
    "            n_jobs=4,  # Use a specific number of jobs to prevent memory overload\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Fit GridSearchCV on the pre-computed PCA data\n",
    "        grid_search.fit(X_train_pca, y_train)\n",
    "        \n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "        \n",
    "        print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        best_score = grid_search.score(X_val_pca, y_val)\n",
    "        print(f\"Validation Accuracy for the best {model_name} model: {best_score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while running GridSearchCV for {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8201706-b1c1-40e2-bd72-b535acba9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- All Implementations Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b792f8-e6e4-4994-aea1-5345ab279d0e",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86407ab-1c19-48d6-a717-de2220eda0c2",
   "metadata": {},
   "source": [
    "## Traditional Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97daf6e-1f23-4039-94c7-cc1db8fe51d1",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6706f609-b199-4543-81af-a1e5ef1bef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Model intialization\n",
    "#lr_model = LogisticRegression()\n",
    "\n",
    "# Training the model\n",
    "#lr_model.fit(X_train,y_train)\n",
    "#print(\"Number of iterations performed:\", lr_model.n_iter_)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "#y_pred = lr_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873abacf-8e3c-479b-b116-5d1b1ae17c87",
   "metadata": {},
   "source": [
    "# Applying Tfidf to word column  -  text_features, applying StandardScaler for other numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c3999f-d9f3-4cf8-b429-6d5dfd0a9701",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ColumnTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- 3. Define the shared preprocessing and PCA steps ---\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[1;32m      3\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      4\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m), text_features),\n\u001b[1;32m      5\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler(), numerical_features)\n\u001b[1;32m      6\u001b[0m     ],\n\u001b[1;32m      7\u001b[0m     remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03mfinal_n_components = 83\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    ('pca', PCA(n_components=final_n_components)),\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m]) \"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# --- 4. Create a dictionary of models to experiment with ---\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ColumnTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "# --- 3. Define the shared preprocessing and PCA steps ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(max_features=500, stop_words='english'), text_features),\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\"\"\"\n",
    "final_n_components = 83\n",
    "\n",
    "pipeline_PCA = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA(n_components=final_n_components)),\n",
    "]) \"\"\"\n",
    "\n",
    "# --- 4. Create a dictionary of models to experiment with ---\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'NaiveBayes': ComplementNB(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# --- 5. Loop through the models, create a pipeline, fit, and score ---\n",
    "print(\"--- Starting Model Experimentation ---\")\n",
    "for model_name, model_instance in models.items():\n",
    "    print(f\"\\nTraining and evaluating the {model_name} model...\")\n",
    "    \n",
    "    # Create the full pipeline for the current model\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model_instance)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        # Fit the pipeline on the training data\n",
    "        full_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model on the validation data\n",
    "        score = full_pipeline.score(X_val, y_val)\n",
    "        \n",
    "        print(f\"Accuracy for {model_name}: {score:.4f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while training {model_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751a4d4-b3aa-43a5-8ddf-4fa155ffb3a2",
   "metadata": {},
   "source": [
    "# Applying PCA to evaluate potential improvements in efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e955cc6-bc57-4bd0-8f20-dc5a4da0225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 3. Define the shared preprocessing and PCA steps ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(max_features=500, stop_words='english'), text_features),\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "final_n_components = 83\n",
    "\n",
    "pipeline_PCA = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA(n_components=final_n_components)),\n",
    "])\n",
    "\n",
    "# --- 4. Create a dictionary of models to experiment with ---\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'XGBoost': XGBClassifier(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    # Note: Naive Bayes works best with non-negative data. PCA can produce negative values, so this may not work.\n",
    "    #'NaiveBayes': ComplementNB(), \n",
    "    # KNN is very slow on high-dimensional data, so it is commented out for faster execution.\n",
    "    # 'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# --- 5. Loop through the models, create a pipeline, fit, and score ---\n",
    "print(\"--- Starting Model Experimentation ---\")\n",
    "for model_name, model_instance in models.items():\n",
    "    print(f\"\\nTraining and evaluating the {model_name} model...\")\n",
    "    \n",
    "    # Create the full pipeline for the current model\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessing_and_pca', pipeline_PCA),\n",
    "        ('model', model_instance)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        # Fit the pipeline on the training data\n",
    "        full_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model on the validation data\n",
    "        score = full_pipeline.score(X_val, y_val)\n",
    "        \n",
    "        print(f\"Accuracy for {model_name}: {score:.4f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while training {model_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc1f98-768f-46ca-9a0f-bfd081f126ef",
   "metadata": {},
   "source": [
    "# Applying GridSearchCV to evaluate potential improvements in efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea82c01-ed53-4cb5-b42f-5174fc8ff360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Model Experimentation with GridSearchCV ---\n",
      "\n",
      "Performing GridSearchCV for the LogisticRegression model...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "d in matmulew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountere\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights.T + intercept  # ndarray, likely C-contiguous\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:336: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for LogisticRegression: {'model__C': 1.0, 'model__solver': 'lbfgs'}\n",
      "Validation Accuracy for the best LogisticRegression model: 0.6303\n",
      "\n",
      "Performing GridSearchCV for the XGBoost model...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:17:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:17:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:17:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: overflow encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:734: RuntimeWarning: invalid value encountered in matmul\n",
      "  matvec=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: divide by zero encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: overflow encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/utils/sparsefuncs.py:735: RuntimeWarning: invalid value encountered in matmul\n",
      "  matmat=lambda x: X @ x - offset @ x,\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Define the shared preprocessing and PCA steps ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(stop_words='english'), text_features),\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Note: The number of components for PCA can also be a hyperparameter to tune.\n",
    "# We'll include it in the param_grids for a more thorough search.\n",
    "pipeline_PCA = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA(n_components=83)),\n",
    "])\n",
    "\n",
    "# --- 3. Create a dictionary of models to experiment with ---\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    # Note: ComplementNB works best with non-negative data. PCA can produce negative values, which may cause an error.\n",
    "    # We will try it, but be aware of the potential issue. \n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'NaiveBayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "# --- 4. Define parameter grids for each model ---\n",
    "# Use the __ (double underscore) to specify pipeline step and parameter\n",
    "param_grids = {\n",
    "    'LogisticRegression': {\n",
    "        'model__C': [0.1, 1.0, 10.0],\n",
    "        'model__solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.05, 0.1, 0.2]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [10, 20, None]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model__n_neighbors': [3, 5, 7],\n",
    "        'model__weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'NaiveBayes': {\n",
    "        'model__alpha': [0.1, 0.5, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- 5. Loop through the models, apply GridSearchCV, and evaluate ---\n",
    "print(\"--- Starting Model Experimentation with GridSearchCV ---\")\n",
    "best_models = {}\n",
    "\n",
    "for model_name, model_instance in models.items():\n",
    "    print(f\"\\nPerforming GridSearchCV for the {model_name} model...\")\n",
    "    \n",
    "    param_grid = param_grids.get(model_name, {})\n",
    "    \n",
    "    if not param_grid:\n",
    "        print(f\"No parameter grid defined for {model_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Create the full pipeline for the current model\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessing_and_pca', pipeline_PCA),\n",
    "        ('model', model_instance)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        # Create the GridSearchCV object\n",
    "        grid_search = GridSearchCV(\n",
    "            full_pipeline, \n",
    "            param_grid, \n",
    "            cv=3, \n",
    "            scoring='accuracy', \n",
    "            n_jobs=-1, \n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Fit GridSearchCV on the training data\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Store the best estimator found\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "        \n",
    "        # Print the results\n",
    "        print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        \n",
    "        # Evaluate the best model on the validation data\n",
    "        best_score = grid_search.score(X_val, y_val)\n",
    "        print(f\"Validation Accuracy for the best {model_name} model: {best_score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while running GridSearchCV for {model_name}: {e}\")\n",
    "\n",
    "print(\"\\n--- GridSearchCV Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d9f61-767d-4b45-bb5b-bbf623d69ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Example of using GridSearchCV to find the best hyperparameters ---\n",
    "print(\"\\n--- Starting GridSearchCV for RandomForestClassifier ---\")\n",
    "\n",
    "# Define the pipeline for GridSearch\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessing_and_pca', pipeline_PCA),\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid to search over.\n",
    "# Note the naming convention: 'step_name__parameter_name'\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [None, 10, 20],\n",
    "    'model__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_jobs=-1, # Use all available CPU cores\n",
    "    verbose=2 # Verbosity level\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Fit the grid search to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print the best parameters and the best score\n",
    "    print(\"\\nBest parameters found:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(f\"\\nBest cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Evaluate the best estimator on the validation set\n",
    "    best_rf_score = grid_search.best_estimator_.score(X_val, y_val)\n",
    "    print(f\"Validation accuracy of the best model: {best_rf_score:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during Grid Search: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524b765-b4c6-466f-89fa-6a76c21f83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic_reg = Pipeline([\n",
    "    ('pipeline_PCA',pipeline_PCA),\n",
    "('logistic_regression',LogisticRegression(random_state=42)),\n",
    "])\n",
    "#Model intialization\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# --- 4. Fit the entire pipeline on the training data ONLY ---\n",
    "print(\"\\nFitting the complete pipeline on the training data...\")\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# --- 5. Evaluate the model on the unseen test data ---\n",
    "score = lr_model.score(X_val, y_val)\n",
    "print(f\"Model accuracy on the test set: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390c619-86b8-405c-86c6-04fe9b9fb3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70b244-21bd-4e11-b6c4-f074430fe2c1",
   "metadata": {},
   "source": [
    "# KNN (K-Nearest Neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8fea0d-a3d7-44d3-8915-baf2152e7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "#Model intialization\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Training the model\n",
    "knn_model.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = lr_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16cde4-eb1f-45a7-b10e-4d11d0295201",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"KNN Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd6f61-2fa2-4c2c-a288-b4ac012aaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "# 1. Generate the confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# 2. Get the unique labels from the test set for display\n",
    "class_labels = y_val.unique()\n",
    "\n",
    "# 3. Create a ConfusionMatrixDisplay object\n",
    "# The 'display_labels' argument provides the labels for the axes.\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "\n",
    "# 4. Plot the confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee44046-28d5-4e7f-997d-55188b8554c6",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ab05d-45c8-4b53-8f5a-26a21a0e5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Model intialization\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Training the model\n",
    "nb_model.fit(X_train,y_train)\n",
    "print(\"Number of iterations performed:\", lr_model.n_iter_)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = nb_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace48b82-d17d-4622-8047-35d4c8f6b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Multinomial Naive Bayes Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165143e-a55a-48b4-962d-2c37591fa900",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35e446-0c3b-4bc5-936c-8527049a0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Model intialization\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Training the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_rf = rf_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d468c55-723b-409b-b729-3dddc1e9a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Classifier Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred_rf):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59474e3-14ce-4b57-86bf-4e265eb4587e",
   "metadata": {},
   "source": [
    "\n",
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f7348-2166-4e04-9517-96c31ee9983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a7ef4-0b54-42d6-83bd-e17cfd568ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can you find any feature which is indicating data leakage, what are the most important feature which contributed to accuracy, find the feature importance tells which made XGboost better. correlation analysos\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 2. Fit the encoder on the training labels and transform both training and test labels\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_val_encoded = le.transform(y_val) # Note: Corrected y_test to y_val as per your variable name\n",
    "\n",
    "# 3. Initialize the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob',\n",
    "                              eval_metric='mlogloss')\n",
    "\n",
    "# 4. Train the model with the NUMERICAL labels\n",
    "# This is the crucial fix: use y_train_encoded\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# 5. Make predictions\n",
    "# Make sure you are passing the correct validation data\n",
    "y_pred_encoded = xgb_model.predict(X_val)\n",
    "\n",
    "# 6. Decode the predictions back to their original labels for readability\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# 7. Evaluate the model using the original labels\n",
    "print(\"XGBoost Classifier Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ffc25-6c91-4ad7-80ed-164333381873",
   "metadata": {},
   "source": [
    "# Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75f0e6-1de9-4e7d-8058-09259af7f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Gradient Boosting Classifier Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred)) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589318c-41e8-4334-b847-20c65dbeba35",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db15ac-1ffc-4624-a2bc-0b131039b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#Model intialization\n",
    "#svc_model = SVC()\n",
    "\n",
    "# Training the model\n",
    "#svc_model.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "#y_pred = svc_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075549e-7cfd-485b-8ce8-752ab873a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" print(\"SVM Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred)) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32467cc0-732c-41f6-81a1-a831815362b2",
   "metadata": {},
   "source": [
    "# Kfold validation and Hyperparameter Tuning and their performance using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d90c0-3292-4950-945c-f44e3f244311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f2758-0b7f-4b9e-998f-6a9ddd4d387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_val_encoded = le.transform(y_val)\n",
    "\n",
    "# Define models and their hyperparameter grids\n",
    "models_and_params = {\n",
    "    'Logistic Regression': (\n",
    "        LogisticRegression(max_iter=1000, random_state=42),\n",
    "        {'model__C': [0.1, 1, 10, 100], 'model__penalty': ['l1', 'l2']}\n",
    "    ),\n",
    "    'Multinomial Naive Bayes': (\n",
    "        MultinomialNB(),\n",
    "        {'model__alpha': [0.1, 0.5, 1.0, 2.0]}\n",
    "    ),\n",
    "    'Random Forest Classifier': (\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {'model__n_estimators': [50, 100, 200], 'model__max_depth': [None, 10, 20]}\n",
    "    ),\n",
    "    'Gradient Boosting Classifier': (\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        {'model__n_estimators': [50, 100], 'model__learning_rate': [0.05, 0.1]}\n",
    "    ),\n",
    "    'XGBoost Classifier': (\n",
    "        xgb.XGBClassifier(objective='multi:softprob', eval_metric='mlogloss', use_label_encoder=False, random_state=42),\n",
    "        {'model__n_estimators': [50, 100], 'model__learning_rate': [0.05, 0.1]}\n",
    "    ),\n",
    "    'Support Vector Machine (SVC)': (\n",
    "        SVC(random_state=42),\n",
    "        {'model__C': [0.1, 1, 10], 'model__kernel': ['linear', 'rbf']}\n",
    "    )\n",
    "}\n",
    "\n",
    "# 4. Set up K-Fold Cross-Validation\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 5. Loop through models, perform tuning, and evaluate\n",
    "for name, (model, params) in models_and_params.items():\n",
    "    print(f\"\\n{'='*50}\\nStarting hyperparameter tuning for: {name}\\n{'='*50}\")\n",
    "\n",
    "    # Use the appropriate target variable for XGBoost\n",
    "    if name == 'XGBoost Classifier':\n",
    "        y_train_target = y_train_encoded\n",
    "        y_val_target = y_val_encoded\n",
    "        # You will need to uncomment this line for XGBoost prediction later\n",
    "        y_val_original = y_val\n",
    "    else:\n",
    "        y_train_target = y_train\n",
    "        y_val_target = y_val\n",
    "    \n",
    "    # Create a pipeline including the TfidfVectorizer.\n",
    "    # This prevents data leakage during cross-validation.\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english')),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=params,\n",
    "        cv=cv_strategy,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Fit the grid search on the raw text data (X_train)\n",
    "    grid_search.fit(X_train, y_train_target)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Best parameters found for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    \n",
    "    # If using XGBoost, decode the predictions back to original labels\n",
    "    if name == 'XGBoost Classifier':\n",
    "        y_pred = le.inverse_transform(y_pred)\n",
    "        y_val_true = y_val_original\n",
    "    else:\n",
    "        y_val_true = y_val\n",
    "\n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_val_true, y_pred):.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val_true, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c291c0a5-ade7-4c2c-bae3-5158148b2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization technique using GridSearchCV\n",
    "#Define models and their hyperparameter grids\n",
    "models_and_params = {\n",
    "    'Logistic Regression': (\n",
    "        LogisticRegression(max_iter=1000, random_state=42),\n",
    "        {'model__C': [0.1, 1, 10, 100], 'model__penalty': ['l1', 'l2']}\n",
    "    ),\n",
    "    'Multinomial Naive Bayes': (\n",
    "        MultinomialNB(),\n",
    "        {'model__alpha': [0.1, 0.5, 1.0, 2.0]}\n",
    "    ),\n",
    "    'Random Forest Classifier': (\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {'model__n_estimators': [50, 100, 200], 'model__max_depth': [None, 10, 20]}\n",
    "    ),\n",
    "   # 'Gradient Boosting Classifier': (\n",
    "   #     GradientBoostingClassifier(random_state=42),\n",
    "   #     {'model__n_estimators': [50, 100], 'model__learning_rate': [0.05, 0.1]}\n",
    "   # ),\n",
    "    'XGBoost Classifier': (\n",
    "        xgb.XGBClassifier(objective='multi:softprob', eval_metric='mlogloss', use_label_encoder=False, random_state=42),\n",
    "        {'model__n_estimators': [50, 100], 'model__learning_rate': [0.05, 0.1]}\n",
    "    )#,\n",
    "    #'Support Vector Machine (SVC)': (\n",
    "    #    SVC(random_state=42),\n",
    "    #    {'model__C': [0.1, 1, 10], 'model__kernel': ['linear', 'rbf']}\n",
    "    #)\n",
    "}\n",
    "\n",
    "# 4. Set up K-Fold Cross-Validation\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 5. Loop through models, perform tuning, and evaluate\n",
    "for name, (model, params) in models_and_params.items():\n",
    "    print(f\"\\n{'='*50}\\nStarting hyperparameter tuning for: {name}\\n{'='*50}\")\n",
    "\n",
    "    # Use the appropriate target variable for XGBoost\n",
    "    if name == 'XGBoost Classifier':\n",
    "        y_train_target = y_train_encoded\n",
    "        y_test_target = y_val_encoded\n",
    "    else:\n",
    "        y_train_target = y_train\n",
    "        y_test_target = y_val\n",
    "\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        #('tfidf', TfidfVectorizer(max_features=5000, stop_words='english')),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=params,\n",
    "        cv=cv_strategy,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train_target)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Best parameters found for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    \n",
    "    # If using XGBoost, decode the predictions back to original labels\n",
    "    if name == 'XGBoost Classifier':\n",
    "        y_pred = le.inverse_transform(y_pred)\n",
    "    \n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b63165-bf6e-49a3-8e3f-f3b7a022edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de284527-2aba-4bab-9a8d-9e326c53e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define a single objective function for all models\n",
    "def objective(params):\n",
    "    \"\"\"Objective function for Hyperopt.\n",
    "    This function takes hyperparameters and returns a loss (negative accuracy)\n",
    "    using K-Fold cross-validation.\n",
    "    \"\"\"\n",
    "    model_name = params.pop('model_type')\n",
    "    \n",
    "    if model_name == 'LogisticRegression':\n",
    "        model = LogisticRegression(**params, solver='liblinear', random_state=42)\n",
    "    elif model_name == 'RandomForestClassifier':\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "    elif model_name == 'GradientBoostingClassifier':\n",
    "        model = GradientBoostingClassifier(**params, random_state=42)\n",
    "    elif model_name == 'MultinomialNB':\n",
    "        model = MultinomialNB(**params)\n",
    "    elif model_name == 'SVC':\n",
    "        model = SVC(**params, random_state=42)\n",
    "    elif model_name == 'XGBClassifier':\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type specified.\")\n",
    "\n",
    "    # Perform K-Fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # We use negative accuracy as the loss to minimize\n",
    "    score = cross_val_score(model, X_train, y_train_target, cv=kf, scoring='accuracy', n_jobs=-1).mean()\n",
    "    loss = 1 - score\n",
    "    \n",
    "    return {'loss': loss, 'status': STATUS_OK, 'model_name': model_name, 'params': params}\n",
    "\n",
    "# 4. Define the search space for each model's hyperparameters\n",
    "space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'model_type': 'LogisticRegression',\n",
    "        'C': hp.loguniform('C_logreg', np.log(0.001), np.log(100.0)),\n",
    "        'penalty': hp.choice('penalty_logreg', ['l1', 'l2'])\n",
    "    },\n",
    "    {\n",
    "        'model_type': 'MultinomialNB',\n",
    "        'alpha': hp.uniform('alpha_mnb', 0.0, 1.0)\n",
    "    },\n",
    "    {\n",
    "        'model_type': 'RandomForestClassifier',\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators_rf', 10, 200, 10)),\n",
    "        'max_depth': scope.int(hp.quniform('max_depth_rf', 3, 20, 1)),\n",
    "        'min_samples_split': hp.uniform('min_samples_split_rf', 0.1, 1.0),\n",
    "        'min_samples_leaf': hp.uniform('min_samples_leaf_rf', 0.1, 0.5)\n",
    "    },\n",
    "    #{\n",
    "    #    'model_type': 'GradientBoostingClassifier',\n",
    "    #    'n_estimators': scope.int(hp.quniform('n_estimators_gb', 50, 250, 10)),\n",
    "    #    'learning_rate': hp.loguniform('learning_rate_gb', np.log(0.01), np.log(0.5)),\n",
    "    #    'max_depth': scope.int(hp.quniform('max_depth_gb', 2, 10, 1))\n",
    "    #},\n",
    "    {\n",
    "        'model_type': 'XGBClassifier',\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators_xgb', 50, 250, 10)),\n",
    "        'learning_rate': hp.loguniform('learning_rate_xgb', np.log(0.01), np.log(0.5)),\n",
    "        'max_depth': scope.int(hp.quniform('max_depth_xgb', 2, 10, 1))\n",
    "    }#,\n",
    "    #{\n",
    "     #   'model_type': 'SVC',\n",
    "     #   'C': hp.loguniform('C_svc', np.log(0.01), np.log(100)),\n",
    "     #   'kernel': hp.choice('kernel_svc', ['linear', 'rbf'])\n",
    "    #}\n",
    "])\n",
    "\n",
    "# 5. Run the optimization\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,  # Number of different hyperparameter combinations to test\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "# 6. Extract and print the best results\n",
    "best_result = sorted(trials.results, key=lambda x: x['loss'])[0]\n",
    "\n",
    "print(\"\\n--- Hyperopt Optimization Results ---\")\n",
    "print(f\"Best Model: {best_result['model_name']}\")\n",
    "print(f\"Best Hyperparameters: {best_result['params']}\")\n",
    "print(f\"Best Validation Accuracy: {1 - best_result['loss']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
